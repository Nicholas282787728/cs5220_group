# New Kernel

While benchmarking matrix multiplication based on Bindel's kernel we also attempted to write a faster one, focusing on multiplying 8x8 matrices (saved in mm_kernel/kdgemm_doublerainbow.c). This was fairly straightforward. Starting with a naive implementation we unrolled the 2 inner loops and replaced adjacent operations with their equivalent SSE instructions. Afterwards it became clear that replacing A and C with their transposes would make all memory accesses to each matrix sequential, improving cache use. This put the kernel on par with Bindel's.

Several other optimizations were tried to no benefit. Unlike Bindel's kernel the basic 8x8 SSE is faster with the Intel compiler than gcc. After reading some documentation on icc we found a flag called 'fast' that makes architecture-specific optimizations and added the equivalent flags for the cluster nodes, but this didn't help. There was no gain from adding more temporary variables to eliminate false dependencies past the 8 in the final version. We also tried reducing the matrix size to 4x4 which actually resulted in a performance decrease.

We eventually did luck into another performance boost. Using Bindel's kernel we had experimented with the -funroll-loops flag and assumed it would do a near optimal job, and thought this would be especially true on a small matrix with size known at compile time. This turned out to be wrong. After adding '#pragma unroll(8)' above the main loop on a whim the kernel jumped to 5500Mflops.

The new kernel was not ready in time to integrate with the main dgemm routine. It is available only in mm_kernel/kdgemm_doublerainbow.c. It is likely some performance would be lost making it work with larger matrices. 